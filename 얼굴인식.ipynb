{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "얼굴인식.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mS0O7T32bOq8"
      },
      "source": [
        "# 얼굴인식\n",
        "1차: 2021.07.14\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VLLr6eKbQMa"
      },
      "source": [
        "# 주석 (코드 돌아가지 않는 부분)\n",
        "\n",
        "import numpy as np  #코드"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zdPr0itBb9YE"
      },
      "source": [
        "# 할 일 정리\n",
        "0. 필요한 라이브러리를 가져온다 (import)   \n",
        "tensorflow, keras, 등등...   \n",
        "imgshow, numpy, ....\n",
        "\n",
        "1. colab 에 데이터 불러오기   \n",
        "\n",
        "2. 모델을 만든다 (CNN 코드를 참고해서)\n",
        "\n",
        "3. face-training-set 으로 모델을 학습시킨다. (train)\n",
        "문제랑 정답을 같이 줘서 모델을 트레ㅇ닝\n",
        "\n",
        "4. 모델이 내놓은 정답이랑, 실제 정답 비교"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y4kB1DbYaaWa",
        "outputId": "0507a76b-a222-4534-b456-badb8b32c416"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xEKf0kveeAIA"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib  #시각화ㅡ 그래프 그리기\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt  #plt.img_show()\n",
        "import os\n",
        "import cv2\n",
        "from os.path import isfile, join\n",
        "import glob\n",
        "import gzip\n",
        "from PIL import Image\n",
        "from scipy import misc"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgxlNc-2eby9"
      },
      "source": [
        "# 딥러닝에 필요한 라이브러리들 import\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras.layers import Input,Conv2D,MaxPooling2D,UpSampling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.preprocessing.image import array_to_img"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OcCYcmw3eep5"
      },
      "source": [
        "\n",
        "# CNN\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.models import load_model\n",
        "from keras.utils.np_utils import to_categorical\n",
        "\n",
        "from keras import layers, regularizers, optimizers, callbacks\n",
        "from collections import defaultdict\n",
        "from keras.optimizers import RMSprop\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "\n",
        "from sklearn.metrics import pairwise_distances_argmin\n",
        "from skimage.io import imread\n",
        "from sklearn.utils import shuffle\n",
        "from skimage import img_as_float\n",
        "\n",
        "from keras import layers\n",
        "from keras import models\n",
        "from keras.utils import np_utils  # to_categorical"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "id": "hND6z2t7e5fN",
        "outputId": "117b1035-6407-4b29-d4b9-c67ef6408421"
      },
      "source": [
        "### 첫번째 데이터 출력해보기\n",
        "img1 = matplotlib.image.imread(join('/content/drive/MyDrive/face-training-set/0001_0001.BMP'))\n",
        "plt.figure()\n",
        "plt.figure(figsize=(24,25))\n",
        "plt.subplot(1,5,1, facecolor='w')\n",
        "plt.imshow(img1, cmap='gray')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f20db375610>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1728x1800 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tEhqMJJif4xm"
      },
      "source": [
        "# 꼭 알아야할 개념\n",
        "### 1. 하이퍼 파라미터 (hyper-parameter)\n",
        "epochs=40, batch_size=16, learning-rate=0.0001, ...   \n",
        "활성화 함수(activation func): relu, softmax 등등의 다양한 활성화 함수 존재\n",
        "\n",
        "### 2. CNN 모델의 layer\n",
        "-> 성능에 많은 영향\n",
        "\n",
        "### 3. 트레이닝셋과 테스트셋\n",
        "트레이닝셋은? 질문과 정답을 같이 준다   \n",
        "테스트셋은? 질문만 주고, 정답과 비교 -> 성능 측정\n",
        "\n",
        "### 4. 성능 개선"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ngXLvQ9gi_jt"
      },
      "source": [
        "# 1. 데이터셋 불러오기\n",
        "트레이닝, 테스트셋 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKJkQOoJfd6M"
      },
      "source": [
        "\n",
        "# 학습 결과 분석을 위한 그래프 구현\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_acc(history, title=None):\n",
        "  # summarize history for accuracy\n",
        "  if not isinstance(history, dict):\n",
        "    history = history.history\n",
        "  plt.plot(history['accuracy'])\n",
        "  plt.plot(history['val_accuracy'])\n",
        "  if title is not None:\n",
        "    plt.title(title)\n",
        "  plt.ylabel('Accuracy')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.legend(['Training', 'Verification'], loc=0)   # 두 선의 이름(Train, Test) 표시\n",
        "\n",
        "def plot_loss(history, title=None):\n",
        "  # summarize history for loss\n",
        "  if not isinstance(history, dict):\n",
        "    history = history.history\n",
        "  plt.plot(history['loss'])             # 학습 데이터로 구한 손실값\n",
        "  plt.plot(history['val_loss'])         # 검증 데이터로 구한 손실값\n",
        "  if title is not None:\n",
        "    plt.title(title)\n",
        "  plt.ylabel('Loss')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.legend(['Training', 'Verification'], loc=0)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "id": "vw2pTJvliSI_",
        "outputId": "4b791a52-f4ed-466f-ce19-3b80c54c7feb"
      },
      "source": [
        "def create_Trainset(folder):\n",
        "   \n",
        "    img_data_array=[]\n",
        "    class_name=[]\n",
        "    \n",
        "    for file in os.listdir(folder):\n",
        "        image_path = os.path.join(folder, file)\n",
        "        image = load_img(image_path, 'rb')\n",
        "        image = img_to_array(image)\n",
        "        \n",
        "        if image.shape[2] == 3:\n",
        "            image = image.mean(2)\n",
        "\n",
        "        img_data_array.append(image)\n",
        "        name_index = file.split(\"_\")\n",
        "        name_index = int(name_index[0])\n",
        "        class_name.append(name_index)\n",
        "        \n",
        "    return np.array(img_data_array), np.array(class_name)\n",
        "\n",
        "\n",
        "def create_Testset(folder):\n",
        "   \n",
        "    img_data_array=[]\n",
        "    class_name=[]\n",
        "    \n",
        "    for file in os.listdir(folder):\n",
        "        image_path = os.path.join(folder, file)\n",
        "        image = load_img(image_path, 'rb')\n",
        "        image = img_to_array(image)\n",
        "        \n",
        "        if image.shape[2] == 3:\n",
        "            image = image.mean(2)\n",
        "\n",
        "        img_data_array.append(image)\n",
        "        name_index = file.split(\".\")\n",
        "        name_index = int(name_index[0])\n",
        "        class_name.append(name_index)\n",
        "        \n",
        "    return np.array(img_data_array), np.array(class_name)\n",
        "\n",
        "# 정규화\n",
        "def normalization(image):  \n",
        "    image = image / image.max()\n",
        "    return image\n",
        "\n",
        "\n",
        "\n",
        "train_PATH = '/content/drive/MyDrive/face-training-set'\n",
        "x_train, y_train = create_Trainset(train_PATH) #불러오기\n",
        "x_train = normalization(x_train) # 정규화 진행\n",
        "\n",
        "test_PATH = '/content/drive/MyDrive/face-test-set'\n",
        "x_test, _ = create_Testset(test_PATH)\n",
        "x_test = normalization(x_test)\n",
        "\n",
        "### 첫번째 데이터 출력해보기\n",
        "img1 = matplotlib.image.imread(join('/content/drive/MyDrive/face-training-set/0001_0001.BMP'))\n",
        "plt.figure()\n",
        "plt.figure(figsize=(24,25))\n",
        "plt.subplot(1,5,1, facecolor='w')\n",
        "plt.imshow(img1, cmap='gray')\n",
        "\n",
        "print('Train images :',x_train.shape)\n",
        "print('Train labels : ', y_train.shape)\n",
        "print('Test images : ', x_test.shape)\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-fd31e9fdb8c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0mtest_PATH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/drive/MyDrive/face-test-set'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_Testset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0mx_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-fd31e9fdb8c3>\u001b[0m in \u001b[0;36mcreate_Testset\u001b[0;34m(folder)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mimage_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/preprocessing/image.py\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[1;32m    294\u001b[0m   \"\"\"\n\u001b[1;32m    295\u001b[0m   return image.load_img(path, grayscale=grayscale, color_mode=color_mode,\n\u001b[0;32m--> 296\u001b[0;31m                         target_size=target_size, interpolation=interpolation)\n\u001b[0m\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/utils.py\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[1;32m    112\u001b[0m                           'The use of `load_img` requires PIL.')\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcolor_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'grayscale'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0;31m# if image is not already an 8-bit, 16-bit or 32-bit grayscale image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ea39jcOvivXC"
      },
      "source": [
        "# 2. CNN 모델 만들기\n",
        "layer 많이 안 쌓고 기본적인 모델로 일단 해보았다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nvIkOUHFkPNw"
      },
      "source": [
        "# 히히\n",
        "### 1. 첫번째 모델 만듦\n",
        "드라이브의 케라스 불러와서 실행했당\n",
        "레이어는 조금 쌓아서 간단하당"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1jM4K29kD3Q"
      },
      "source": [
        "import keras"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HxA79Fm9iuBq",
        "outputId": "8c29eab6-9fe8-484b-8c5e-310cfb714702"
      },
      "source": [
        "model = keras.Sequential([\n",
        "    keras.layers.Flatten(input_shape=(56, 46)),\n",
        "    keras.layers.Dense(256, activation='relu'),\n",
        "    keras.layers.Dense(351, activation='softmax')\n",
        "])\n",
        "\n",
        "# loss 함수로 sparse_categorical_crossentropy 사용\n",
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()   # 모델 확인하기\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten (Flatten)            (None, 2576)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               659712    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 351)               90207     \n",
            "=================================================================\n",
            "Total params: 749,919\n",
            "Trainable params: 749,919\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pj98VNURi79B"
      },
      "source": [
        "model.fit(x_train, y_train, epochs=30)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}